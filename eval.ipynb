{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/richard/miniconda3/envs/dl/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMapping ade20k-150 -> universal\n",
      "\tMapping bdd -> universal\n",
      "\tMapping cityscapes-19 -> universal\n",
      "\tMapping coco-panoptic-133 -> universal\n",
      "\tMapping idd-39 -> universal\n",
      "\tMapping mapillary-public65 -> universal\n",
      "\tMapping sunrgbd-37 -> universal\n",
      "\tMapping ade20k-150-relabeled -> universal\n",
      "\tMapping bdd-relabeled -> universal\n",
      "\tMapping cityscapes-19-relabeled -> universal\n",
      "\tMapping cityscapes-34-relabeled -> universal\n",
      "\tMapping coco-panoptic-133-relabeled -> universal\n",
      "\tMapping idd-39-relabeled -> universal\n",
      "\tMapping mapillary-public65-relabeled -> universal\n",
      "\tMapping sunrgbd-37-relabeled -> universal\n",
      "\n",
      "\tCreating 1x1 conv for test datasets...\n",
      "Totally 20210 samples in val set.\n",
      "Checking image&label pair val list done!\n",
      "image folder path: data/mseg_dataset/ADE20K/\n",
      "text path: mseg-api/mseg/dataset_lists/ade20k-150-relabeled/list/train.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10105/10105 [43:44<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 20210\n",
      "Accuracy: 0.5836145441590743\n",
      "IoU: 0.18291134191472844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# This file will run through an entire dataset to report Accuracy and IoU.\n",
    "\n",
    "# Import Libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "from Lseg.lseg_trainer import LSegModule\n",
    "from Lseg.lseg_net import LSegNet\n",
    "\n",
    "from Lseg.data.util import get_labels, get_dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torchmetrics import Accuracy, JaccardIndex\n",
    "import tqdm\n",
    "\n",
    "# METRICS\n",
    "NUM_CLASSES = 195\n",
    "accuracy_fn = Accuracy(task=\"multiclass\", num_classes=NUM_CLASSES).to(device=\"cuda\")\n",
    "iou_fn = JaccardIndex(task=\"multiclass\", num_classes=NUM_CLASSES).to(device=\"cuda\")\n",
    "\n",
    "# Labels\n",
    "labels = get_labels()\n",
    "\n",
    "config = {\n",
    "    \"batch_size\": 2,  # 6\n",
    "    \"base_lr\": 0.04,\n",
    "    \"max_epochs\": 50,\n",
    "    \"num_features\": 512,\n",
    "}\n",
    "\n",
    "net = LSegNet(\n",
    "    labels=labels,\n",
    "    features=config[\"num_features\"],\n",
    ")\n",
    "\n",
    "# Load Model - replace with actual\n",
    "load_checkpoint_path = r\"checkpoints/checkpoint_epoch=0-val_loss=4.7304.ckpt\"\n",
    "model = LSegModule.load_from_checkpoint(\n",
    "    load_checkpoint_path,\n",
    "    max_epochs=config[\"max_epochs\"],\n",
    "    model=net,\n",
    "    num_classes=len(labels),\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    base_lr=config[\"base_lr\"],\n",
    ")\n",
    "model = model.to(device=\"cuda\").float()\n",
    "\n",
    "# Load ADE20K validation dataset\n",
    "test_dataset = get_dataset(dataset_name=\"ade20k\", get_train=False)\n",
    "test_dataloaders = DataLoader(test_dataset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=8)\n",
    "\n",
    "# Evaluate accuracy and IoU\n",
    "mean_accuracy = 0.0\n",
    "mean_iou = 0.0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X, y in tqdm.tqdm(test_dataloaders):\n",
    "        X = X.to(device=\"cuda\").float()\n",
    "        y = y.to(device=\"cuda\").float()\n",
    "        output = model(X)\n",
    "        prediction = torch.argmax(output, dim=1)\n",
    "        mean_accuracy += accuracy_fn(prediction, y).item()\n",
    "        mean_iou += iou_fn(prediction, y).item()\n",
    "\n",
    "mean_accuracy = mean_accuracy / len(test_dataloaders)\n",
    "mean_iou = mean_iou / len(test_dataloaders)\n",
    "print(f\"Number of examples: {len(test_dataset)}\")\n",
    "print(f\"Accuracy: {mean_accuracy}\")\n",
    "print(f\"IoU: {mean_iou}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
